# cogs/llm.py
import discord
from discord.ext import commands
from utils.helpers import create_embed
from utils.system_prompt import get_system_prompt
from utils.ollama_handler import OllamaHandler
from utils.db_handler import DatabaseHandler
import os
from typing import Optional, Dict, Any, Set
from datetime import datetime

class LLM(commands.Cog):
    def __init__(self, bot):
        self.bot = bot
        self.db = DatabaseHandler()
        
        # Initialize Ollama handler with proper timeout
        ollama_url = os.getenv('OLLAMA_URL', 'http://ollama:11434')
        self.ollama = OllamaHandler(base_url=ollama_url)
        
        # Define available models and their configurations
        self.model_configs = {
            'chat': {
                'name': 'deepseek-r1:8b',
                'description': 'A technical assistant focused on programming help',
            },
            'mention': {
                'name': 'dolphin3',
                'description': 'The rude bot personality for mentions',
            }
        }
        
        # Initialize prompts after bot is ready to avoid circular imports
        self.bot.loop.create_task(self.initialize_prompts())

    async def initialize_prompts(self):
        """Initialize default prompts in database"""
        # Define default prompts
        default_prompts = {
            'deepseek-r1:8b': """You are an AI assistant integrated into a Discord bot. You are direct and informal in your responses.
You have a good understanding of programming and technology.
You should provide helpful and accurate information while maintaining a casual tone.
You can use code blocks and formatting when sharing code or technical information.""",
            
            'dolphin3': get_system_prompt()  # The original rude bot prompt
        }
        
        # Initialize prompts in database
        for model_name, default_prompt in default_prompts.items():
            if not self.db.get_prompt(model_name):
                self.db.set_prompt(model_name, default_prompt, self.bot.user.id)

    def get_valid_models(self) -> Set[str]:
        """Get set of valid model names"""
        return {config['name'] for config in self.model_configs.values()}

    def get_model_prompt(self, model_name: str) -> Optional[str]:
        """Get the current prompt for a model"""
        return self.db.get_prompt(model_name)

    async def send_chunked_message(self, ctx, content: str, reply_to=None):
        """Send a message in chunks if it's too long"""
        if len(content) <= 2000:
            if reply_to:
                await reply_to.reply(content)
            else:
                await ctx.send(content)
            return

        chunks = [content[i:i+2000] for i in range(0, len(content), 2000)]
        for i, chunk in enumerate(chunks):
            if i == 0 and reply_to:
                await reply_to.reply(chunk)
            else:
                if reply_to:
                    await reply_to.channel.send(chunk)
                else:
                    await ctx.send(chunk)

    @commands.hybrid_command(
        name="set_prompt",
        description="[ADMIN] Set the system prompt for a specific model"
    )
    @commands.has_permissions(administrator=True)
    async def set_prompt(self, ctx, model: str, *, prompt: str):
        """Set the system prompt for a specific model"""
        try:
            valid_models = self.get_valid_models()
            if model not in valid_models:
                embed = create_embed(
                    title="Error",
                    description=f"Invalid model. Available models: {', '.join(valid_models)}",
                    color=discord.Color.red().value
                )
                await ctx.send(embed=embed)
                return

            self.db.set_prompt(model, prompt, ctx.author.id)
            
            embed = create_embed(
                title="System Prompt Updated",
                description=f"Updated system prompt for {model}",
                color=discord.Color.green().value
            )
            embed.add_field(name="New Prompt", value=prompt[:1024], inline=False)
            
            await ctx.send(embed=embed)

        except Exception as e:
            embed = create_embed(
                title="Error",
                description=f"Failed to update prompt: {str(e)}",
                color=discord.Color.red().value
            )
            await ctx.send(embed=embed)

    @commands.hybrid_command(
        name="get_prompt",
        description="View the current system prompt for a model"
    )
    async def view_prompt(self, ctx, model: str):
        """View the current system prompt for a model"""
        try:
            valid_models = self.get_valid_models()
            if model not in valid_models:
                embed = create_embed(
                    title="Error",
                    description=f"Invalid model. Available models: {', '.join(valid_models)}",
                    color=discord.Color.red().value
                )
                await ctx.send(embed=embed)
                return

            prompt = self.get_model_prompt(model)
            if not prompt:
                embed = create_embed(
                    title="Error",
                    description=f"No prompt found for model {model}",
                    color=discord.Color.red().value
                )
                await ctx.send(embed=embed)
                return

            history = self.db.get_prompt_history(model)
            
            embed = create_embed(
                title=f"System Prompt for {model}",
                description=prompt[:2048],  # Discord embed description limit
                color=discord.Color.blue().value
            )
            
            if history:
                last_update = history[0]
                embed.add_field(
                    name="Last Updated",
                    value=f"By {last_update['updated_by_name']} on {last_update['last_updated']}",
                    inline=False
                )
            
            await ctx.send(embed=embed)

        except Exception as e:
            embed = create_embed(
                title="Error",
                description=f"Failed to get prompt: {str(e)}",
                color=discord.Color.red().value
            )
            await ctx.send(embed=embed)

    @commands.hybrid_command(
        name="reset_prompt",
        description="[ADMIN] Reset the system prompt to default for a model"
    )
    @commands.has_permissions(administrator=True)
    async def reset_prompt(self, ctx, model: str):
        """Reset the system prompt to its default value"""
        try:
            valid_models = self.get_valid_models()
            if model not in valid_models:
                embed = create_embed(
                    title="Error",
                    description=f"Invalid model. Available models: {', '.join(valid_models)}",
                    color=discord.Color.red().value
                )
                await ctx.send(embed=embed)
                return

            # Get default prompt and reset
            default_prompt = get_system_prompt() if model == 'dolphin3' else self.get_model_prompt(model)
            if not default_prompt:
                embed = create_embed(
                    title="Error",
                    description=f"No default prompt found for model {model}",
                    color=discord.Color.red().value
                )
                await ctx.send(embed=embed)
                return

            self.db.set_prompt(model, default_prompt, ctx.author.id)
            
            embed = create_embed(
                title="System Prompt Reset",
                description=f"Reset system prompt for {model} to default",
                color=discord.Color.green().value
            )
            embed.add_field(
                name="Default Prompt",
                value=default_prompt[:1024],
                inline=False
            )
            
            await ctx.send(embed=embed)

        except Exception as e:
            embed = create_embed(
                title="Error",
                description=f"Failed to reset prompt: {str(e)}",
                color=discord.Color.red().value
            )
            await ctx.send(embed=embed)

    @commands.Cog.listener()
    async def on_message(self, message):
        """Handle mentions using dolphin model"""
        if message.author == self.bot.user:
            return
            
        if self.bot.user in message.mentions:
            content = message.content.replace(f'<@{self.bot.user.id}>', '').strip()
            if content:
                try:
                    async with message.channel.typing():
                        model_name = self.model_configs['mention']['name']
                        response = await self.ollama.generate_response(
                            message.author.id,
                            content,
                            model_name,
                            self.get_model_prompt(model_name)
                        )
                    
                    if response.startswith("Error:"):
                        embed = create_embed(
                            title="Error",
                            description=response,
                            color=discord.Color.red().value
                        )
                        await message.reply(embed=embed)
                    else:
                        await self.send_chunked_message(None, response, reply_to=message)
                
                except Exception as e:
                    embed = create_embed(
                        title="Error",
                        description=f"An error occurred: {str(e)}",
                        color=discord.Color.red().value
                    )
                    await message.reply(embed=embed)

    @commands.hybrid_command(
        name="chat",
        description="Chat with the smart-ish bot"
    )
    async def chat(self, ctx, *, message: str):
        """Chat with deepseek model with conversation memory"""
        await ctx.defer()
        
        try:
            async with ctx.typing():
                model_name = self.model_configs['chat']['name']
                response = await self.ollama.generate_response(
                    ctx.author.id,
                    message,
                    model_name,
                    self.get_model_prompt(model_name)
                )
            
            if response.startswith("Error:"):
                embed = create_embed(
                    title="Error",
                    description=response,
                    color=discord.Color.red().value
                )
                await ctx.send(embed=embed)
            else:
                await self.send_chunked_message(ctx, response)
            
        except Exception as e:
            embed = create_embed(
                title="Error",
                description=f"An error occurred: {str(e)}",
                color=discord.Color.red().value
            )
            await ctx.send(embed=embed)

    @commands.hybrid_command(
        name="clear_chat",
        description="Clear your chat history"
    )
    async def clear_chat(self, ctx):
        """Clear the conversation history"""
        try:
            self.ollama.clear_history(ctx.author.id)
            embed = create_embed(
                title="Chat History Cleared",
                description="Your conversation history has been cleared.",
                color=discord.Color.green().value
            )
            await ctx.send(embed=embed)
        except Exception as e:
            embed = create_embed(
                title="Error",
                description=f"Failed to clear history: {str(e)}",
                color=discord.Color.red().value
            )
            await ctx.send(embed=embed)

    @commands.hybrid_command(
        name="show_history",
        description="Show your chat history"
    )
    async def show_history(self, ctx):
        """Display the conversation history"""
        try:
            history = self.ollama.get_history(ctx.author.id)
            
            if not history:
                embed = create_embed(
                    title="Chat History",
                    description="No chat history found.",
                    color=discord.Color.blue().value
                )
                await ctx.send(embed=embed)
                return

            embed = create_embed(
                title="Chat History",
                description="Here's your recent chat history:",
                color=discord.Color.blue().value
            )

            for i, msg in enumerate(history, 1):
                role = "You" if msg["role"] == "user" else "Bot"
                content = msg["content"][:1000] + "..." if len(msg["content"]) > 1000 else msg["content"]
                embed.add_field(
                    name=f"{i}. {role}",
                    value=content,
                    inline=False
                )

            await ctx.send(embed=embed, ephemeral=True)

        except Exception as e:
            embed = create_embed(
                title="Error",
                description=f"Failed to show history: {str(e)}",
                color=discord.Color.red().value
            )
            await ctx.send(embed=embed)

async def setup(bot):
    await bot.add_cog(LLM(bot))